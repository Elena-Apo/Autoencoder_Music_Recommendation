{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2JvIZd65fYa"
   },
   "source": [
    "# The Autocoder for music recommendtion system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "LZX__owZ5l3T"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from typing import Literal\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "swZnAbpv5_UA"
   },
   "outputs": [],
   "source": [
    "music_dataset = load_dataset(\"yandex/yambda\", \"flat-50m\", streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MpP4PpdI5_Hh"
   },
   "outputs": [],
   "source": [
    "class YambdaDataset:\n",
    "    INTERACTIONS = frozenset([\n",
    "        \"likes\", \"listens\", \"multi_event\", \"dislikes\", \"unlikes\", \"undislikes\"\n",
    "    ])\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_type: Literal[\"flat\", \"sequential\"] = \"flat\",\n",
    "        dataset_size: Literal[\"50m\", \"500m\", \"5b\"] = \"50m\"\n",
    "    ):\n",
    "        self.dataset_type = dataset_type\n",
    "        self.dataset_size = dataset_size\n",
    "\n",
    "    def interaction(self, event_type: Literal[\n",
    "        \"likes\", \"listens\", \"multi_event\", \"dislikes\", \"unlikes\", \"undislikes\"\n",
    "    ]) -> Dataset:\n",
    "        return self._download(f\"{self.dataset_type}/{self.dataset_size}\", f\"{event_type}.parquet\")\n",
    "\n",
    "    def audio_embeddings(self) -> Dataset:\n",
    "        return self._download(\"\", \"embeddings.parquet\")\n",
    "\n",
    "    def album_item_mapping(self) -> Dataset:\n",
    "        return self._download(\"\", \"album_item_mapping.parquet\")\n",
    "\n",
    "    def artist_item_mapping(self) -> Dataset:\n",
    "        return self._download(\"\", \"artist_item_mapping.parquet\")\n",
    "\n",
    "    def genre_item_mapping(self) -> Dataset:\n",
    "        return self._download(\"\", \"genre_item_mapping.parquet\")\n",
    "\n",
    "    def user_item_mapping(self) -> Dataset:\n",
    "        return self._download(\"\", \"user_item_mapping.parquet\")\n",
    "\n",
    "    @staticmethod\n",
    "    def _download(data_dir: str, file: str) -> Dataset:\n",
    "        data = load_dataset(\"yandex/yambda\", data_dir=data_dir, data_files=file)\n",
    "        return data[\"train\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KKIbYjpIEA7m"
   },
   "outputs": [],
   "source": [
    "# Инициализация загрузчика\n",
    "dataset = YambdaDataset(\"flat\", \"50m\")\n",
    "\n",
    "listens_ds = dataset.interaction(\"listens\").to_pandas()\n",
    "likes_ds = dataset.interaction(\"likes\").to_pandas()\n",
    "dislikes_ds = dataset.interaction(\"dislikes\").to_pandas()\n",
    "unlikes_ds = dataset.interaction(\"unlikes\").to_pandas()\n",
    "undislikes_ds = dataset.interaction(\"undislikes\").to_pandas()\n",
    "# embeddings_ds = dataset.audio_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   uid  timestamp  item_id  is_organic  played_ratio_pct  track_length_seconds\n",
      "0  100      39420  8326270           0               100                   170\n",
      "1  100      39420  1441281           0               100                   105\n",
      "2  100      39625   286361           0               100                   185\n",
      "3  100      40110   732449           0               100                   240\n",
      "4  100      40360  3397170           0                46                   130\n",
      "   uid  timestamp  item_id  is_organic\n",
      "0  100      44755   732449           1\n",
      "1  100    1155860  6568592           0\n",
      "2  100    1259125  5411243           1\n",
      "3  100    1260005  7371186           0\n",
      "4  100    1263935  4943655           0\n",
      "   uid  timestamp  item_id  is_organic\n",
      "0  100    3087560  9170134           1\n",
      "1  100    3936560  8661238           1\n",
      "2  100   20432825  4927727           1\n",
      "3  400    2980800   399811           1\n",
      "4  400    3157520  1575108           1\n",
      "   uid  timestamp  item_id  is_organic\n",
      "0  100    3087555  5038504           1\n",
      "1  100    3087555  9170134           1\n",
      "2  100    4012270  7833676           0\n",
      "3  100   21210445  7610592           0\n",
      "4  100   21210465  7610592           0\n",
      "   uid  timestamp  item_id  is_organic\n",
      "0  100    7895900  9170134           1\n",
      "1  100    7895900  5038504           1\n",
      "2  900   25364045  6092542           1\n",
      "3  900   25364045  6501913           1\n",
      "4  900   25364045  3628099           1\n"
     ]
    }
   ],
   "source": [
    "# Вывод шапок\n",
    "print(listens_ds.head())\n",
    "print(likes_ds.head())\n",
    "print(dislikes_ds.head())\n",
    "print(unlikes_ds.head())\n",
    "print(undislikes_ds.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1cva1JSg7QDo"
   },
   "outputs": [],
   "source": [
    "# Создаём  таблицу только с нужными колонками и флагом\n",
    "listens = listens_ds[['uid', 'item_id', 'played_ratio_pct']].copy()\n",
    "\n",
    "likes = likes_ds[['uid', 'item_id']].copy()\n",
    "likes['liked'] = True\n",
    "\n",
    "dislikes = dislikes_ds[['uid', 'item_id']].copy()\n",
    "dislikes['disliked'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kbFaqEm6EA-X"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   uid  item_id  played_ratio_pct  liked  disliked\n",
      "0  100  8326270               100  False     False\n",
      "1  100  1441281               100  False     False\n",
      "2  100   286361               100  False     False\n",
      "3  100   732449               100   True     False\n",
      "4  100  3397170                46  False     False\n"
     ]
    }
   ],
   "source": [
    "listens = listens.merge(\n",
    "    likes,\n",
    "    on=['uid', 'item_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "listens['liked'] = listens['liked'].fillna(False)\n",
    "\n",
    "listens = listens.merge(\n",
    "    dislikes,\n",
    "    on=['uid', 'item_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "listens['disliked'] = listens['disliked'].fillna(False)\n",
    "\n",
    "print(listens.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uid                 0\n",
      "item_id             0\n",
      "played_ratio_pct    0\n",
      "liked               0\n",
      "disliked            0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>item_id</th>\n",
       "      <th>played_ratio_pct</th>\n",
       "      <th>liked</th>\n",
       "      <th>disliked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>8326270</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>286361</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>732449</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>7849270</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>1449307</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47166492</th>\n",
       "      <td>1000000</td>\n",
       "      <td>1578810</td>\n",
       "      <td>99</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47166520</th>\n",
       "      <td>1000000</td>\n",
       "      <td>4952290</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47166531</th>\n",
       "      <td>1000000</td>\n",
       "      <td>6320264</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47166550</th>\n",
       "      <td>1000000</td>\n",
       "      <td>1464852</td>\n",
       "      <td>99</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47166557</th>\n",
       "      <td>1000000</td>\n",
       "      <td>1578810</td>\n",
       "      <td>99</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28277654 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              uid  item_id  played_ratio_pct  liked  disliked\n",
       "0             100  8326270               100  False     False\n",
       "2             100   286361               100  False     False\n",
       "3             100   732449               100   True     False\n",
       "5             100  7849270               100  False     False\n",
       "6             100  1449307               100  False     False\n",
       "...           ...      ...               ...    ...       ...\n",
       "47166492  1000000  1578810                99  False     False\n",
       "47166520  1000000  4952290               100  False     False\n",
       "47166531  1000000  6320264               100  False     False\n",
       "47166550  1000000  1464852                99  False     False\n",
       "47166557  1000000  1578810                99  False     False\n",
       "\n",
       "[28277654 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Поиск NAN, выбросов и дубликатов\n",
    "print(listens.isnull().sum())\n",
    "listens[listens.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "B0RA58IjYS1I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              uid  item_id  played_ratio_pct  interaction\n",
      "0             100  8326270               100            0\n",
      "1             100  1441281               100            0\n",
      "2             100   286361               100            0\n",
      "3             100   732449               100            1\n",
      "4             100  3397170                46            0\n",
      "...           ...      ...               ...          ...\n",
      "47166555  1000000  3369589                99            0\n",
      "47166556  1000000  8120372                99            0\n",
      "47166557  1000000  1578810                99            0\n",
      "47166558  1000000  3732104               100            0\n",
      "47166559  1000000  2978154                74            0\n",
      "\n",
      "[47166560 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create interaction column\n",
    "listens['interaction'] = listens['liked'] * 1 + listens['disliked'] * -1\n",
    "\n",
    "# Drop liked and disliked columns\n",
    "listens = listens.drop(columns=['liked', 'disliked'])\n",
    "\n",
    "# Display the transformed DataFrame\n",
    "print(listens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = listens.describe()\n",
    "stats_df.to_excel(\"statistic.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-iNVEtq3-orl",
    "outputId": "1110f69f-cbfd-45dc-cef3-dbca09f5a4de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity of the listens table: 0.2128\n"
     ]
    }
   ],
   "source": [
    "# Calculate total number of elements in the table\n",
    "total_elements = listens.size\n",
    "\n",
    "# Count zero or empty values\n",
    "zero_or_empty_count = (listens == 0).sum().sum() + listens.isnull().sum().sum()\n",
    "\n",
    "# Calculate sparsity\n",
    "sparsity = zero_or_empty_count / total_elements\n",
    "\n",
    "print(f\"Sparsity of the listens table: {sparsity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "YCDagjsFEBAv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Sparsity: 0.21\n",
      "Logical Sparsity: 0.30\n"
     ]
    }
   ],
   "source": [
    "# Calculate standard sparsity: proportion of zero or empty values to total elements\n",
    "# For boolean columns, False is considered sparse\n",
    "num_elements = listens.size\n",
    "num_sparse_elements = (listens == False).sum().sum() + listens.isnull().sum().sum()\n",
    "standard_sparsity = num_sparse_elements / num_elements\n",
    "\n",
    "# Calculate logical sparsity: rows where both liked and disliked are False\n",
    "logical_sparse_rows = listens[(listens['interaction'] == 0) & (listens['played_ratio_pct'] < 70)]\n",
    "logical_sparsity = len(logical_sparse_rows) / len(listens)\n",
    "\n",
    "print(f\"Standard Sparsity: {standard_sparsity:.2f}\")\n",
    "print(f\"Logical Sparsity: {logical_sparsity:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "listens['uid_enc'] = encoder.fit_transform(listens['uid'])\n",
    "listens['item_id_enc'] = encoder.fit_transform(listens['item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HuTh_BbHZlEk",
    "outputId": "53549b4a-f899-42cb-f4bf-e31f1e6d943c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              uid  item_id  played_ratio_pct  interaction  uid_enc   \n",
      "0             100  8326270               100            0        0  \\\n",
      "1             100  1441281               100            0        0   \n",
      "2             100   286361               100            0        0   \n",
      "3             100   732449               100            1        0   \n",
      "4             100  3397170                46            0        0   \n",
      "...           ...      ...               ...          ...      ...   \n",
      "47166555  1000000  3369589                99            0     7125   \n",
      "47166556  1000000  8120372                99            0     7125   \n",
      "47166557  1000000  1578810                99            0     7125   \n",
      "47166558  1000000  3732104               100            0     7125   \n",
      "47166559  1000000  2978154                74            0     7125   \n",
      "\n",
      "          item_id_enc  item_id_freq  \n",
      "0              128364          5014  \n",
      "1               22169            57  \n",
      "2                4463          1464  \n",
      "3               11487           617  \n",
      "4               52312          1219  \n",
      "...               ...           ...  \n",
      "47166555        51876          2551  \n",
      "47166556       125166          3552  \n",
      "47166557        24307          5636  \n",
      "47166558        57568          5603  \n",
      "47166559        45810          5385  \n",
      "\n",
      "[39510922 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Удаляем треки, которые слушали менее 25 раз\n",
    "track_counts = listens.groupby('item_id_enc').size()\n",
    "valid_tracks = track_counts[track_counts >= 25].index\n",
    "listens = listens[listens['item_id_enc'].isin(valid_tracks)]\n",
    "\n",
    "# Удаляем пользователей, которые не поставили ни одного лайка\n",
    "user_likes = listens.groupby('uid')['interaction'].sum()\n",
    "valid_users = user_likes[user_likes > 0].index\n",
    "listens = listens[listens['uid'].isin(valid_users)]\n",
    "\n",
    "# Display the transformed\n",
    "print(listens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       played_ratio_scaled  interaction_scaled    uid_scaled   item_scaled\n",
      "count         3.951092e+07        3.951092e+07  3.951092e+07  3.951092e+07\n",
      "mean         -1.336530e-16        7.333292e-17  4.972041e-01  5.024049e-01\n",
      "std           1.000000e+00        1.000000e+00  2.879984e-01  2.876649e-01\n",
      "min          -1.454058e+00       -2.821177e+00  0.000000e+00  0.000000e+00\n",
      "25%          -1.318251e+00       -5.571720e-01  2.474386e-01  2.554118e-01\n",
      "50%           8.093802e-01       -5.571720e-01  4.936140e-01  5.020597e-01\n",
      "75%           8.093802e-01        1.706833e+00  7.454035e-01  7.510506e-01\n",
      "max           2.144809e+00        1.706833e+00  1.000000e+00  1.000000e+00\n"
     ]
    }
   ],
   "source": [
    "# Масштабируем поведенческие признаки\n",
    "scaler_behavior = StandardScaler()\n",
    "behavior_scaled = scaler_behavior.fit_transform(listens[['played_ratio_pct', 'interaction']])\n",
    "\n",
    "# Масштабируем категориальные признаки (если не используешь Embedding)\n",
    "scaler_uid = MinMaxScaler()\n",
    "scaler_item = MinMaxScaler()\n",
    "\n",
    "uid_scaled = scaler_uid.fit_transform(listens[['uid_enc']])\n",
    "item_scaled = scaler_item.fit_transform(listens[['item_id_enc']])\n",
    "combined_array = np.hstack([behavior_scaled, uid_scaled, item_scaled])\n",
    "\n",
    "combined_df = pd.DataFrame(\n",
    "    combined_array,\n",
    "    columns=['played_ratio_scaled', 'interaction_scaled', 'uid_scaled', 'item_scaled']\n",
    ")\n",
    "\n",
    "stats = combined_df.describe()\n",
    "print(stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(combined_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = combined_df.shape[1]\n",
    "encoding_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 4)]               0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 128)               640       \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_16 (Activation)  (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_17 (Activation)  (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 64)                2112      \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_18 (Activation)  (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_19 (Activation)  (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,460\n",
      "Trainable params: 22,692\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Размер входного вектора\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "\n",
    "# ЭНКОДЕР\n",
    "x = Dense(128)(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Dense(64)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "encoded = Dense(32, activation='relu')(x)  # Боттлнек\n",
    "\n",
    "# ДЕКОДЕР (зеркально)\n",
    "x = Dense(64)(encoded)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Dense(128)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "# Выходной слой\n",
    "decoded = Dense(input_dim, activation='linear')(x)\n",
    "\n",
    "# Компиляция модели\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "autoencoder.compile(optimizer=Adam(learning_rate=0.0001), loss='mse')\n",
    "\n",
    "# Структура модели\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15617/15617 [==============================] - ETA: 0s - loss: 0.0685\n",
      "Epoch 1: val_loss improved from inf to 0.00308, saving model to best_autoencoder.h5\n",
      "15617/15617 [==============================] - 530s 34ms/step - loss: 0.0685 - val_loss: 0.0031\n",
      "Epoch 2/10\n",
      "15617/15617 [==============================] - ETA: 0s - loss: 0.0181\n",
      "Epoch 2: val_loss improved from 0.00308 to 0.00210, saving model to best_autoencoder.h5\n",
      "15617/15617 [==============================] - 529s 34ms/step - loss: 0.0181 - val_loss: 0.0021\n",
      "Epoch 3/10\n",
      "15617/15617 [==============================] - ETA: 0s - loss: 0.0163\n",
      "Epoch 3: val_loss did not improve from 0.00210\n",
      "15617/15617 [==============================] - 535s 34ms/step - loss: 0.0163 - val_loss: 0.0021\n",
      "Epoch 4/10\n",
      "15617/15617 [==============================] - ETA: 0s - loss: 0.0154\n",
      "Epoch 4: val_loss did not improve from 0.00210\n",
      "15617/15617 [==============================] - 536s 34ms/step - loss: 0.0154 - val_loss: 0.0021\n",
      "Epoch 5/10\n",
      "   21/15617 [..............................] - ETA: 8:21 - loss: 0.0150"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[106], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m early_stop \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(filepath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_autoencoder.h5\u001b[39m\u001b[38;5;124m'\u001b[39m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mautoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath='best_autoencoder.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "autoencoder.fit(X_train, X_train, epochs=10, batch_size=2024, shuffle=True, \n",
    "                validation_data=(X_test, X_test), callbacks=[early_stop, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246944/246944 [==============================] - 228s 924us/step - loss: 0.0022\n",
      "Test reconstruction loss: 0.0022\n",
      "246944/246944 [==============================] - 230s 929us/step\n"
     ]
    }
   ],
   "source": [
    "loss = autoencoder.evaluate(X_test, X_test)\n",
    "print(f\"Test reconstruction loss: {loss:.4f}\")\n",
    "\n",
    "# Получаем реконструированные данные\n",
    "X_pred = autoencoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "2632515",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3651\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 2632515",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[108], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Выбираем один пример для отображения\u001b[39;00m\n\u001b[0;32m      2\u001b[0m example_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, X_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m----> 3\u001b[0m original \u001b[38;5;241m=\u001b[39m \u001b[43mX_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mexample_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      4\u001b[0m reconstructed \u001b[38;5;241m=\u001b[39m X_pred[example_index]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Строим график\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3760\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3759\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3760\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3762\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3654\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3655\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3656\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 2632515"
     ]
    }
   ],
   "source": [
    "# Выбираем один пример для отображения\n",
    "example_index = np.random.randint(0, X_test.shape[0])\n",
    "original = X_test[example_index]\n",
    "reconstructed = X_pred[example_index]\n",
    "\n",
    "# Строим график\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(original, label='Оригинальные данные', color='blue', marker=\"o\" )\n",
    "plt.plot(reconstructed, label='Реконструкция автокодера', color='green', linestyle='dashed', marker=\"o\")\n",
    "plt.title('Сравнение оригинала и реконструкции')\n",
    "plt.xlabel('Признаки / временные шаги')\n",
    "plt.ylabel('Значение')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Сохраняем модель в формате TensorFlow SavedModel\n",
    "# autoencoder.save('Models/Autoencoder_Music_Recommendation', save_format=\"keras\")\n",
    "autoencoder.save('Models/Autoencoder_Music_Recommendation_low_loss', save_format=\"keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                96        \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 658\n",
      "Trainable params: 658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Для формата SavedModel\n",
    "# autoencoder = tf.keras.models.load_model('Models/Autoencoder_Music_Recommendation.keras')\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя ошибка реконструкции: 0.002224\n",
      "Медианная ошибка: 0.000688\n",
      "Максимальная ошибка: 0.566495\n",
      "Минимальная ошибка: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Получаем реконструкции\n",
    "# X_pred = autoencoder.predict(X_test)\n",
    "\n",
    "# Вычисляем ошибку реконструкции для каждого примера\n",
    "errors = np.mean(np.square(X_test - X_pred), axis=1)\n",
    "\n",
    "stats_error = pd.Series(errors).describe()\n",
    "stats_error.to_excel(\"statistic_error.xlsx\")\n",
    "\n",
    "# Статистика\n",
    "print(f\"Средняя ошибка реконструкции: {np.mean(errors):.6f}\")\n",
    "print(f\"Медианная ошибка: {np.median(errors):.6f}\")\n",
    "print(f\"Максимальная ошибка: {np.max(errors):.6f}\")\n",
    "print(f\"Минимальная ошибка: {np.min(errors):.6f}\")\n",
    "\n",
    "# # Гистограмма ошибок\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.hist(errors, bins=100, color='teal', alpha=0.7)\n",
    "# plt.title('Распределение ошибки реконструкции')\n",
    "# plt.xlabel('Ошибка (MSE)')\n",
    "# plt.ylabel('Количество примеров')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
